<a align="center" href="https://doi.org/10.15161/oar.it/eb6em-v6t60"><img src="https://www.openaccessrepository.it/badge/DOI/10.15161/oar.it/eb6em-v6t60.png"></a>


# UAV Photogrammetry Digital Twin Creation Scripts

This repository contains a collection of Python scripts designed for generating digital twins from UAV photogrammetry data. Building upon examples from the [Agisoft Metashape](https://www.agisoft.com/) Scripts [repository](https://github.com/agisoft-llc/metashape-scripts), which is licensed under the MIT License.

## Overview

This project provides a suite of scripts that strategically address different computational needs for the creation of digital twins using UAV (Unmanned Aerial Vehicle) photogrammetry techniques. From a straightforward monolithic workflow to highly modular, parallel, and specialized classification implementations, these scripts offer flexible solutions for processing aerial imagery, generating 3D models, and creating digital representations of real-world environments. 

- **Monolithic Workflow** ([`demo_process.py`](demo/demo_process.py)): A single script for end-to-end digital twin generation on a single computational node, offering simplicity and automated execution with default settings.

- **Modular Workflow** ([`step_workflow.py`](step_workflow.py)): A modularized approach that provides granular control over each photogrammetric processing step, enhancing flexibility, reproducibility and project management for single-node execution.

- **Parallel and Distributed Workflow** ([`network_script.py`](networkTask/network_script.py)): An implementation leveraging Agisoft Metashape's network processing capabilities to distribute computationally intensive tasks across multiple worker nodes, ideal for large datasets and accelerated processing (require floating license).

- **Rename images segmentation mask** ([`rename_mask.py`](rename_mask.py)): The script renames png-masks generated by label studio with json-mini.

- **Point Cloud Classification and Feature Extraction** ([`mask_classification_workflow.py`](mask_classification_workflow.py)): A specialized script for precise point cloud segmentation and classification using image-based masks, enabling the isolation of specific features or damaged areas.

### Dependencies

This project requires some Python packages to run correctly. These packages are listed in the [`requirements.txt`](requirements.txt) file included in this project.

To install these dependencies, run the following command:

```bash
pip install -r requirements.txt
```

### Project layout
```bash
HaMMon-UAV-digital-twin/
├── assets/        
│   └── Metashape-2.2.1....whl # Metashape Python module 2.2.1 (Linux, Mac, Win)
├── demo/         # Folder containing demo code
│   └── demo_process.py     # Main demo code running UAV-digital-twin v1.0 (full workflow)
├── docker/        # Folder containing docker image
├── networkTasks/            # Scripts for parallel and distributed processing
│   ├── network_script.py       # Main distributed workflow script for running UAV-digital-twin v2
│   ├── export_worker_info.py   # Script to export network worker information
│   └── export_monitor_info.py  # Script to process worker info for monitoring
├── reports/       # Folder cointaing scripts for monitoring data analysis
│   ├── report.ipynb    # Jupyter notebooks for running data analysis
│   ├── report.py       # Python code for running data analysis
│   └── sample_data/
│       └── system.csv  # File of data sample   
├── src/          # Folder code for UAV-digital-twin (UML in the doc)
│   ├── geographic_projection.py
│   ├── mesh_processor.py
│   ├── photo_processor.py
│   ├── point_cloud_processor.py
│   ├── progress_printer.py
│   ├── project.py
│   ├── settings.py
│   ├── singleton_meta.py
│   └── system_monitor.py
├── test/         # Folder containing unit tests code
├── config.json   # E.g. configuration file to execute most of the steps
├── config.yaml   # E.g. configuration files to export data
├── mask_classification_workflow.py # Script to point cloud classification
├── rename_mask.py  # Script renames label studio masks
├── requirements.txt    # Text file that lists all package dependencies required to run the project correctly
└── step_workflow.py    # Main code for running UAV-digital-twin v1.1 (single task)
```

## Implementations

To use these scripts, you will need to have Agisoft Metashape Professional Edition installed on your system. Follow the instructions provided by Agisoft for installation and setup. Once installed, simply clone this repository and run the scripts using Python. These scripts are not intended to be used inside the Metashape app GUI. Each script may require specific parameters to be set, so make sure to refer to the documentation provided with each script for detailed usage instructions.

---
### Monolithic Workflow

This script offers a complete, automated pipeline for digital twin creation. It executes all necessary photogrammetric steps sequentially on a single machine, requiring no manual parameter adjustments beyond input/output paths. It's best suited for standardized projects where a consistent, hands-off workflow is preferred.

Usage:

```bash
python demo/demo_process.py <path_to_image_folder> [output_folder]
```
- <path_to_image_folder>: Path to the directory containing UAV images.

- [output_folder]: (Optional) Desired destination for output files. If omitted, a timestamped folder is created in a default location
---
### Modular Workflow

This implementation provides granular control over the photogrammetric process by breaking it down into individual, manageable tasks. It allows users to execute specific steps, adjust parameters, and resume workflows from any completed stage. It's ideal for projects requiring fine-tuned control on a single computational node.

Usage:

Tasks can be specified via command-line arguments or a configuration file.

```bash
python step_workflow.py -i <path/to/folder/images> -e <"task1:param1,param2 task2:paramA,paramB"> [-o <resulting/directory>]
python step_workflow.py -i <path/to/folder/images> -c <config.json> [-o <resulting/directory>]
```
- -i: path to the input image folder.
- -e: specifies individual tasks and their parameters (e.g., "matchPhotos:downscale=2 alignCameras"). Tasks must be enclosed in quotes if they contain spaces or multiple parameters.
- -o: (Optional) path to the output directory.
- -c: Path to a configuration file (e.g., config.json or config.yaml) detailing the workflow steps and parameters.

Show all available commands:
```bash
python step_workflow.py --help
```
To run the integrated unit test
```bash
python -m unittest
```
---
### Parallel and Distributed Workflow 
Designed for scalability, this script leverages Agisoft Metashape's native network processing to distribute computationally tasks across multiple worker nodes. This significantly reduces processing times for large datasets and is ideal for high-throughput photogrammetry projects.

Usage:

Before running, ensure your Metashape network processing server is configured and accessible, and set the METASHAPE_SERVER environment variable to its IP address.

```bash
export METASHAPE_SERVER="<your_server_ip>" 
python network_tasks/network_script.py <path_to_image_folder> <path_to_output_folder>
```
- <path_to_image_folder>: Path to the directory containing UAV images.

- <path_to_output_folder>: Destination for project files and results.
---

### Point Cloud Classification and Feature Extraction

It allows users to identify, isolate, or assign specific classes to regions of interest (e.g., damaged areas, specific objects) based on visual shape segmentation defined in the original UAV images aligned.

Usage:

```bash
python point_cloud_classifier.py --project <path_to_project.psx> --output_dir <path_to_output_folder> --masks_dir <path_to_masks_folder> --classification_type <type_classification_set> [--invert_masks]
```
- --project: path to the Metashape project file (.psx or .psz).

- --output_dir: path to the output directory for the classified dense cloud export.

- --masks_dir: path to the directory containing image masks (<camera_label>_mask.png).

- --classification_type: specifies the target Metashape point class (e.g., "ground", "building", "high_vegetation", "car", "manmade"). Refer to [Metashape Classification](https://agisoft.freshdesk.com/support/solutions/articles/31000148866-point-cloud-classification) for a full list of supported types classification.

- --invert_masks: (Optional flag) If set, imported masks will be inverted, allowing selection of areas outside the masked regions.

## Citations

If you find this work useful, please consider citing the following reference:

* **Text/APA Format:**

    M. Imbrosciano et al., "The Cloud-HPC infrastructure for Hazard Mapping and vulnerability Monitoring (HaMMon)," 2025 33rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP), Turin, Italy, 2025, pp. 309-316, doi: 10.1109/PDP66500.2025.00050. keywords: {Quantum computing;Clouds;High performance computing;Hazards;Artificial intelligence;Forecasting;Photogrammetry;Monitoring;Testing;Drones;Cloud;HPC;Kubernetes;ASfM;Artificial Intelligence;Post-Event Analysis;Hazard Management;Drone;Photogrammetry},


* **BibTeX Format:**

    ```bibtex
    @INPROCEEDINGS{10974787,
    author={Imbrosciano, Mauro and Sciacca, Eva and Vitello, Fabio and Pelonero, Leonardo and Franchina, Francesco and Becciani, Ugo and Colonnelli, Iacopo and Medić, Doriana},
    booktitle={2025 33rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)}, 
    title={The Cloud-HPC infrastructure for Hazard Mapping and vulnerability Monitoring (HaMMon)}, 
    year={2025},
    volume={},
    number={},
    pages={309-316},
    keywords={Quantum computing;Clouds;High performance computing;Hazards;Artificial intelligence;Forecasting;Photogrammetry;Monitoring;Testing;Drones;Cloud;HPC;Kubernetes;ASfM;Artificial Intelligence;Post-Event Analysis;Hazard Management;Drone;Photogrammetry},
    doi={10.1109/PDP66500.2025.00050}}
    ```

## License

The scripts in this repository are distributed under the terms of the MIT License. See the [LICENSE](LICENSE) file for details.

## Acknowledgements

We would like to express our gratitude to Agisoft LLC for providing the examples that served as the foundation for these scripts.

This work is supported by Italian Research Center on High Performance Computing Big Data and Quantum Computing (ICSC), project funded by European Union - NextGenerationEU - and National Recovery and Resilience Plan (NRRP) - Mission 4 Component 2 within the activities of Spoke 3 (Astrophysics and Cosmos Observations).